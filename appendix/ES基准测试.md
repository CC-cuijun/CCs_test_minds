# ES基准测试

## 存储能力测试

全量数据批量存储

|线程数|提交条数|提交间隔（ms）|90%响应时间(单位:ms)|tps|cpu利用率|备注|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|1|50|0|440|3|25%||
|2|50|0|690|4|40%||
|3|50|0|1506|4|40%||
|4|50|0|1683|3.5|35%||
|5|50|0|2530|3|30%||
|10|50|0|5400|3|30%||
|15|50|0|15047|2|30%||
|20|50|0||||ES节点死掉|
|1|10|0|165|8|4%||
|5|10|0|380|18|8%||
|10|10|0|681|28|30%||
|15|10|0|1348|25|25%||
|20|10|0|1771|15|30%||

全量数据单条存储

|线程数|提交条数|提交间隔（ms）|90%响应时间(单位:ms)|tps|cpu利用率|备注|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|100|1|0|238|160|40%||
|200|1|0|1010|280|50%||
|300|1|0|1874|250|50%||
|400|1|0|4122|200|50%||



GPS数据批量存储

|线程数|提交条数|提交间隔（ms）|90%响应时间(单位:ms)|tps|cpu利用率|备注|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|50|50|0|646|100|20%||
|70|50|0|904|100|50%||
|100|50|0|2052|70|40%||

GP数据单条存储

|线程数|提交条数|提交间隔（ms）|90%响应时间(单位:ms)|tps|cpu利用率|备注|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|100|1|0|||||

## 集群平行扩展能力及配置测试

全量数据批量存储

|线程数|提交条数|提交间隔（ms）|90%响应时间(单位:ms)|tps|cpu利用率|node|shards|replicas|备注|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|2|50|0|508|5|30%|5|9|1||
|2|50|0|690|4|40%|3|5|1||
|5|50|0|1534|4|35%|5|9|1||
|5|50|0|2530|3|30%|3|5|1||
|5|50|0|1033|7|master:10%,slave:55%|5(2master/3slave)|5|1||
|7|50|0|1338|8|master:10%,slave:60%|5(2master/3slave)|5|1||
|7|50|0|1382|8|master:10%,slave:55%|5(1master/4slave)|5|1||
|7|50|0|1534|6|master:10%,slave:50%|5(1master/4slave)|9|1||
|7|50|0|1772|5|master:10%,slave:80%|3(1master/2slave)|5|1||
|2|100|0|1103|2|master:5%,slave:30%|5(1master/4slave)|5|1||
|4|100|0|1613|3|master:5%,slave:40%|5(1master/4slave)|5|1||
|6|100|0|2159|4|master:10%,slave:40%|5(1master/4slave)|6|1||
|5|100|0|1994|4|master:10%,slave:40%|5(1master/4slave)|6|1||


总结：
* 平行扩展能力：data-node增加一倍，TPS增加约3/4（样本数据太小，即TPS太小，可能存在误差）
* 配置：mater不做数据存储，性能可提升一倍；
* 配置：shards配置数量要均衡分配满足：每个节点分配的shards数*节点数=shards总数*（备份数+1）
* 配置：shards数合适即可(每个节点约2-3个)，太多的shards数量会导致效率下降
* 设置not_analyzed变化不明显（不生效？）
* 据说ES在数据量达到100g以后，性能下降很厉害，需要尝试；


## 新一轮测试
* 磁盘空间不够时ES会自动均衡到磁盘空间更充裕的节点上，导致某个节点的IO开销大，CPU利用率很高
* 验证ES在数据量达到100g以后，性能并无明显下降；

|health| status| index|             uuid |                  pri| rep| docs.count |docs.deleted| store.size| pri.store.size|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|green  |open   |test  |            Hu4LgOWeQ1ySSDDWA4LRCQ  | 6  | 1   |26676371     |       0     |97.7gb      |   49.3gb|

|线程数|提交条数|提交间隔（ms）|90%响应时间(单位:ms)|tps|cpu利用率|node|shards|replicas|备注|
|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
|5|100|0|1355|5|master:10%,slave:40%|5(1master/4slave)|6|1||
|5|1200|0|8906|1|master:30%,slave:60%|5(1master/4slave)|6|1||
|5|1200|0|8261|1|master:30%,slave:70%|5(1master/4slave)|10|1||
|5|1200|0|9547|1|master:20%,slave:50%|5(1master/4slave)|4|1||
|5|1200|0|13401|1|master:15%,slave:40%|5(1master/4slave)|2|1||



## 测试过程记录

#### 第一轮
对ES的性能进行了第一轮压测，情况如下：
* 性能瓶颈在ES的存储上；
* ES的配置参数几经调整，也未能有量级上的变化
* 保存全量信号速度约300条/s，此时ES服务器CPU利用率超60%
* 减小数据量后，ES的存储速度明显增大，存储GPS信息约4000条/s（注：位置信息实际不存储ES，此处只做数据存储速度对比），此时ES服务器CPU利用率约40%

本轮优化建议:
可能需要减小索引量，选取一个折中的量级；

#### 第二轮
对ES存储做了一些优化后，如下：
* 将保存ES部分单独拉出成新模块;
* 调整了data中每个信号的状态值，不做索引；
* 调整配置参数：
    * 单次拉取kafka消息600条：      maxPollRecords: 600
    * 并发线程数调整为15个：        process-thread: 15
    * 队列线程调整为200：  thread.num: 200

* 新模块消费kafka速度约900+条/s（全量数据）
* 备注：启用两个节点,速度约1300+条/s,ES集群已达瓶颈，cpu利用率达80%；
